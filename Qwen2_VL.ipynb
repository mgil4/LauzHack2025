{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dog is sitting on the floor near the front door, looking outside.\n"
     ]
    }
   ],
   "source": [
    "# Codi que funciona per single image:\n",
    "import base64 \n",
    "from openai import OpenAI \n",
    "client = OpenAI( base_url=\"https://router.huggingface.co/v1\", api_key=\"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\", ) \n",
    "image_path = \"dog.jpg\" \n",
    "\n",
    "with open(image_path, \"rb\") as f: \n",
    "    image_bytes = f.read() \n",
    "image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\") \n",
    "\n",
    "completion = client.chat.completions.create( \n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct:hyperbolic\", \n",
    "    messages=[ { \"role\": \"user\", \n",
    "                \"content\": [ \n",
    "                { \"type\": \"text\", \n",
    "                 \"text\": \"This image comes from a security camera at my home. Describe only what is happening that is relevant to me as the property owner. Focus on people, animals, vehicles, or objects interacting with my property, and any unusual or noteworthy activity. Do NOT describe the property or the camera itself, and do NOT give suggestions or opinions. Keep the description concise, objective, and suitable for a quick alert message.\" },\n",
    "                   { \"type\": \"image_url\",\n",
    "                     \"image_url\": { \"url\": f\"data:image/jpg;base64,{image_base64}\" } } ] } ], ) \n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person wearing a dark cap and long-sleeve shirt walks into the frame from the left, turns around, walks out of the frame, and exits to the right.\n"
     ]
    }
   ],
   "source": [
    "# Codi que funciona per 4 imatges que extreu com a frames espaiats del video:\n",
    "import base64 \n",
    "from openai import OpenAI \n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "client = OpenAI( base_url=\"https://router.huggingface.co/v1\", api_key=\"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\", ) \n",
    "\n",
    "def load_image_as_base64(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def extract_frames(video_path, max_frames=4, padding_ratio=0.05):\n",
    "    \"\"\"\n",
    "    Extract up to max_frames frames evenly spaced through the video,\n",
    "    avoiding using the very first and very last frames by adding padding.\n",
    "    Saves frames as videoframe_0001.jpg, ..., videoframe_0004.jpg.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "    if frame_count == 0:\n",
    "        cap.release()\n",
    "        return []\n",
    "\n",
    "    # Apply padding to avoid the first and last frames\n",
    "    pad = int(frame_count * padding_ratio)\n",
    "    start = pad\n",
    "    end = max(frame_count - pad, start + 1)   # ensure valid range\n",
    "\n",
    "    # Limit number of frames (max 4)\n",
    "    num_frames = min(max_frames, max(1, end - start))\n",
    "\n",
    "    # Compute evenly spaced frame indices inside the padded region\n",
    "    if num_frames == 1:\n",
    "        indices = [start]\n",
    "    else:\n",
    "        indices = [\n",
    "            int(start + i * (end - start - 1) / (num_frames - 1))\n",
    "            for i in range(num_frames)\n",
    "        ]\n",
    "\n",
    "    saved = []\n",
    "    for i, frame_no in enumerate(indices):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        out_name = f\"videoframe_{i+1:04d}.jpg\"\n",
    "        cv2.imwrite(out_name, frame)\n",
    "        saved.append(out_name)\n",
    "\n",
    "    cap.release()\n",
    "    return saved\n",
    "\n",
    "video_path = r\"video\\\\man_approaching.mp4\"\n",
    "saved_frames = extract_frames(video_path)\n",
    "frame_paths = sorted(glob.glob(\"videoframe_*.jpg\"))\n",
    "frame_images = [load_image_as_base64(path) for path in frame_paths]\n",
    "\n",
    "completion = client.chat.completions.create( \n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct:hyperbolic\", \n",
    "    messages=[ { \"role\": \"user\", \n",
    "                \"content\": [ \n",
    "                { \"type\": \"text\", \n",
    "                 \"text\": \"You are a security assistant analyzing images from a home camera. Describe only what is relevant to the property owner: people, animals, vehicles, or objects interacting with the property, and any unusual or noteworthy activity. Do NOT describe the camera, the property itself, or give suggestions or opinions. Keep your description concise, clear, and suitable for a quick alert. Consider all images together as frames from the same event, and interpret the activity based on the event as a whole.\" },\n",
    "                { \"type\": \"image_url\",\n",
    "                     \"image_url\": { \"url\": f\"data:image/jpg;base64,{frame_images[0]}\" } },\n",
    "                { \"type\": \"image_url\",\n",
    "                     \"image_url\": { \"url\": f\"data:image/jpg;base64,{frame_images[1]}\" } },\n",
    "                { \"type\": \"image_url\",\n",
    "                     \"image_url\": { \"url\": f\"data:image/jpg;base64,{frame_images[2]}\" } },\n",
    "                { \"type\": \"image_url\",\n",
    "                     \"image_url\": { \"url\": f\"data:image/jpg;base64,{frame_images[3]}\" } },                 \n",
    "                 ] } ], ) \n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
